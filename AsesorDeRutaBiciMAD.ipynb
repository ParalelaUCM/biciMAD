{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AsesorDeRutaBiciMAD.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOHBYtj6oenPgTm0lqtg4AZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParalelaUCM/biciMAD/blob/master/AsesorDeRutaBiciMAD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6JLekeSkduf",
        "colab_type": "text"
      },
      "source": [
        "# **Setup**\n",
        "\n",
        "Instalamos y configuramos las herramientas necesarias para empezar a trabajar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dvQgdvjkcPT",
        "colab_type": "code",
        "outputId": "ab96d869-ec64-4394-ed8b-c8bb3504ce56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!apt-get install openjdk-8-jdk\n",
        "\"\"\"\n",
        "#!apt install unzip ya no lo usamos\n",
        "\"\"\"\n",
        "!apt-get install unrar\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!pip install pyspark"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libxxf86dga1 openjdk-8-jdk-headless openjdk-8-jre\n",
            "  openjdk-8-jre-headless x11-utils\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source visualvm icedtea-8-plugin libnss-mdns\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libxxf86dga1 openjdk-8-jdk openjdk-8-jdk-headless\n",
            "  openjdk-8-jre openjdk-8-jre-headless x11-utils\n",
            "0 upgraded, 10 newly installed, 0 to remove and 32 not upgraded.\n",
            "Need to get 40.7 MB of archives.\n",
            "After this operation, 153 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1,041 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-extra all 2.37-1 [1,953 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java all 0.33.3-20ubuntu0.1 [34.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java-jni amd64 0.33.3-20ubuntu0.1 [28.3 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre-headless amd64 8u252-b09-1~18.04 [27.5 MB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre amd64 8u252-b09-1~18.04 [69.8 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk-headless amd64 8u252-b09-1~18.04 [8,250 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk amd64 8u252-b09-1~18.04 [1,622 kB]\n",
            "Fetched 40.7 MB in 2s (19.5 MB/s)\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "(Reading database ... 144467 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../1-fonts-dejavu-core_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../2-fonts-dejavu-extra_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../3-x11-utils_7.7+3build1_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+3build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../4-libatk-wrapper-java_0.33.3-20ubuntu0.1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../5-libatk-wrapper-java-jni_0.33.3-20ubuntu0.1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../6-openjdk-8-jre-headless_8u252-b09-1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u252-b09-1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jre:amd64.\n",
            "Preparing to unpack .../7-openjdk-8-jre_8u252-b09-1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre:amd64 (8u252-b09-1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../8-openjdk-8-jdk-headless_8u252-b09-1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u252-b09-1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk:amd64.\n",
            "Preparing to unpack .../9-openjdk-8-jdk_8u252-b09-1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk:amd64 (8u252-b09-1~18.04) ...\n",
            "Setting up fonts-dejavu-core (2.37-1) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-1) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u252-b09-1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u252-b09-1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "Setting up x11-utils (7.7+3build1) ...\n",
            "Setting up libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
            "Setting up openjdk-8-jre:amd64 (8u252-b09-1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n",
            "Setting up openjdk-8-jdk:amd64 (8u252-b09-1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unrar is already the newest version (1:5.5.8-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n",
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/e4/5c15ab8d354c4e3528510821865e6748209a9b0ff6a1788f4cd36cc2a5dc/pyspark-2.4.6.tar.gz (218.4MB)\n",
            "\u001b[K     |████████████████████████████████| 218.4MB 63kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 54.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.6-py2.py3-none-any.whl size=218814406 sha256=84d1875b13440072bd21e0050e288b9655a090d118c0c5b90a396fde993719ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/5e/6a/17e906c94ec7246f260330a66e44a06a0809033ba2738a74a8\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1Yn_yv0kFQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics as stats\n",
        "from pyspark import SparkContext"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wewQ_aLlkFx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sc = SparkContext()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xB2HI4RlCAv",
        "colab_type": "text"
      },
      "source": [
        "# **Descargamos los datasets de bicimad**\n",
        "Descargaremos cada dataset de la web oficial de biciMAD.\n",
        "La función descarga usa los paquete Beautiful Soup y request, automatizando la obtención de los archivos. Los renombraremos a '.zip' o '.rar' para poder descomprimirlos y una vez descomprimidos los movemos a la carpeta 'datasets'. Por último eliminamos los ficheros comprimidos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zynUfS6zlO2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Estructura de carpetas para el dataset\n",
        "!mkdir dataset\n",
        "!cd dataset/\n",
        "!mkdir dataset/usages\n",
        "!mkdir dataset/stations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csOz4j3ziLix",
        "colab_type": "code",
        "outputId": "f9af97ee-9e41-4e10-c7d7-90ff18c2c85b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "!pip install patool\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import os\n",
        "import zipfile\n",
        "import patoolib\n",
        "\n",
        "#datos de páginas web para la descarga de los dataset\n",
        "pagina = \"https://opendata.emtmadrid.es\"\n",
        "url = requests.get(\"https://opendata.emtmadrid.es/Datos-estaticos/Datos-generales-(1)\")\n",
        "html_doc = url.text\n",
        "soup = BeautifulSoup(html_doc, 'html.parser')\n",
        "meses_l = [None, \"enero\",\"febrero\",\"marzo\",\"abril\",\"mayo\",\"junio\",\"julio\",\n",
        "           \"agosto\",\"septiembre\",\"octubre\",\"noviembre\",\"diciembre\"]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting patool\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/52243ddff508780dd2d8110964320ab4851134a55ab102285b46e740f76a/patool-1.12-py2.py3-none-any.whl (77kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 18.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.3MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDRJY_d_iv_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def descarga(mes,año):\n",
        "  for link in soup.find_all('a'):\n",
        "    l = link.get('title')\n",
        "    if isinstance(l,str):\n",
        "      if meses_l[mes] in l.lower() and str(año) in l:\n",
        "        if \"uso\" in l:\n",
        "          print(l)\n",
        "          enlace = link.get('href')\n",
        "          url = pagina+enlace\n",
        "          r = requests.get(url, allow_redirects=True)\n",
        "          open('temp.aspx', 'wb').write(r.content)\n",
        "          os.rename(\"temp.aspx\",\"temp.zip\")\n",
        "          try:\n",
        "            with zipfile.ZipFile(\"/content/temp.zip\", 'r') as zip_ref:\n",
        "              zip_ref.extractall(\"/content/dataset/usages\")\n",
        "            os.remove(\"/content/temp.zip\")\n",
        "          except:\n",
        "            os.rename(\"temp.zip\",\"temp.rar\")\n",
        "            patoolib.extract_archive(\"temp.rar\", outdir=\"/content/dataset/usages\")\n",
        "            os.remove(\"/content/temp.rar\")\n",
        "        elif \"estaciones\" in l:\n",
        "          print(l)\n",
        "          enlace = link.get('href')\n",
        "          url = pagina+enlace\n",
        "          r = requests.get(url, allow_redirects=True)\n",
        "          open('temp.aspx', 'wb').write(r.content)\n",
        "          os.rename(\"temp.aspx\",\"temp.zip\")\n",
        "          try:\n",
        "            with zipfile.ZipFile(\"/content/temp.zip\", 'r') as zip_ref:\n",
        "              zip_ref.extractall(\"/content/dataset/stations\")\n",
        "            os.remove(\"/content/temp.zip\")\n",
        "          except:\n",
        "            os.rename(\"temp.zip\",\"temp.rar\")\n",
        "            patoolib.extract_archive(\"temp.rar\", outdir=\"/content/dataset/stations\")\n",
        "            os.remove(\"/content/temp.rar\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raadBW_0iygh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1,7):\n",
        "  descarga(i,2019)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l1JrKnQlPbm",
        "colab_type": "text"
      },
      "source": [
        "# **Creamos los RDD**\n",
        "Una vez tenemos las bases de datos descargadas vamos a codificarlas de forma cómoda."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2_J09HfldNw",
        "colab_type": "text"
      },
      "source": [
        "Para tener los datos almacenados de una forma cómoda primero creamos un diccionario cuya clave va a ser un string con el mes y el año del dataset y como valor va a tener el rdd asociado al uso por usuario de ese mes.\n",
        "\n",
        "La funcion `mapper_usages` nos servirá para crear la rdd más legible. Nos quedaremos con los datos necesarios y cada linea la codificaremos como un diccionario."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKXOxYtPlUPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rdd_usages = {} "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ1WZW9ylnFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mapper_usages(line):\n",
        "  data = json.loads(line)\n",
        "  user = data['user_type']\n",
        "  user_day = data['user_day_code']\n",
        "  start = data['idunplug_station']\n",
        "  end = data['idplug_station']\n",
        "  date = data['unplug_hourTime']['$date'][0:10]\n",
        "  hora = data['unplug_hourTime']['$date'][11:19]\n",
        "  time = data['travel_time']\n",
        "  age = data['ageRange']\n",
        "  try:\n",
        "    track = data['track']\n",
        "  except:\n",
        "    track = None\n",
        "  return {\"user_type\": user,\n",
        "          \"user_day_code\": user_day,\n",
        "          \"start\": start,\n",
        "          \"end\": end,\n",
        "          \"travel_time\": time,\n",
        "          \"date\": date,\n",
        "          \"hour\": hora,\n",
        "          \"age\": age,\n",
        "          \"track\": track}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9pIrqUclrQl",
        "colab_type": "code",
        "outputId": "c6666dfe-7e5c-4ff7-eb0f-e0ea4be938bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "directory = 'dataset/usages'\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith(\".json\"):\n",
        "      #Nos quedamos con la fecha del dataset en formato YYYYMM\n",
        "      name = filename.split(\"_\")[0]\n",
        "      rdd_usages[name] = sc.textFile(os.path.join(directory, filename)).map(mapper_usages)\n",
        "      #DEBUG starts\n",
        "      print(name)\n",
        "      #DEBUG ends\n",
        "    else:\n",
        "        continue"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "201906\n",
            "201905\n",
            "201901\n",
            "201904\n",
            "201902\n",
            "201903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jHkWWJcBg9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Juntamos todos los datos de los meses en uno solo dataset, y lo metemos también al diccionario.\n",
        "rdd_usages['2019_01a06'] = rdd_usages['201901'].union(rdd_usages['201902'].union(rdd_usages['201903'].union(rdd_usages['201904'].union(rdd_usages['201905'].union(rdd_usages['201906'])))))\n",
        "#rdd_usages['2019_01a06'] = rdd_usages['201901'].concat(rdd_usages['201902'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHVwJiV1EtYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rdd_usages['2019_01a06'].take(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muBX-1kTly_Y",
        "colab_type": "text"
      },
      "source": [
        "Por otro lado un diccionario cuya clave va a ser tambien un string con el mes y el año del dataset y como valor va a tener el rdd asociado a la ocupación de las estaciones en ese mes.\n",
        "\n",
        "Aquí usaremos la funcion `mapper_stations` para acomodar los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do-vrp0Ul3uZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rdd_stations = {} "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhR9BSlSl5xZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mapper_stations(line):\n",
        "  data = json.loads(line)\n",
        "  day = data['_id'][0:10]\n",
        "  hour = data['_id'][11:27]\n",
        "  station = data['stations']\n",
        "  return {\"day\": day, \"hour\": hour, \"station\": station}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLEPxjcBl77p",
        "colab_type": "code",
        "outputId": "17dc502f-da9b-4c24-e72d-fe7eb83eee8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "directory = 'dataset/stations'\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith(\".json\"):\n",
        "      #Nos quedamos con la fecha del dataset en formato YYYYMM\n",
        "      name = filename.split(\"_\")[2].split(\".\")[0]\n",
        "      rdd_stations[name] = sc.textFile(os.path.join(directory, filename)).map(mapper_stations)\n",
        "      #DEBUG starts\n",
        "      print(name)\n",
        "      #DEBUG ends\n",
        "    else:\n",
        "        continue"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "201905\n",
            "201906\n",
            "201903\n",
            "201902\n",
            "201904\n",
            "201901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ6aliu9ZzP5",
        "colab_type": "text"
      },
      "source": [
        "# **Asesor de ruta BiciMAD**\n",
        "\n",
        "Aquí, dada una estación de origen, una de destino y una hora a la que se quiera salir, calcularemos el tiempo medio para realizar el trayecto así como cuantas bicicletas suele haber libres en las estaciones y si suele haber hueco en la estación final para poder colocar la bicicleta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2tidU4UYv2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import statistics as stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNeo1hjcZ4ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "origen = input('Estación de la que se desea partir: ')\n",
        "destino = input('Estación a la que se desea llegar: ')\n",
        "hora_Viaje = int(input('Hora a la que se desea realizar el viaje(HH): '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4moerLTadQ_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Funcion que se queda con los viajes alrededor de la hora solicitada\n",
        "def rangoTiempo(hora, rango, hora_target):\n",
        "    hora = hora.split(\":\")\n",
        "    h = int(hora[0])\n",
        "    m = int(hora[1])\n",
        "    hora = h + m/60.0\n",
        "    print(hora)\n",
        "    if (hora_target - rango < 0):\n",
        "      return((hora < hora_target + rango) or 24 + hora_target - rango < hora)\n",
        "    else:\n",
        "      return(hora_target - rango < hora and hora < hora_target + rango)\n",
        "\n",
        "rangoTiempo('17:00:00', 1.5, 17)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47fzpaTaZ-Lb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Aquí hacemos un primer filtro quedándonos con todos los trayectos que parten de \n",
        "#la estación origen y terminan en la estacion destino\n",
        "rddInvierno_viaje_dia = rdd_usages['2019_01a06'].filter(lambda x: x['start'] == int(origen) and x['end'] == int(destino))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5SSjkq6UUrz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Debug\n",
        "print('Total de viajes similares al del cliente sin tener en cuenta el horario: ', rddInvierno_viaje_dia.count())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTOYZ27BaGn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Y ahora filtramos ya solo en el rango de horas especificado. \n",
        "#En este caso 1.5h alrededor de la hora elegida\n",
        "rddInvierno_viaje = rddInvierno_viaje_dia.filter(lambda x: rangoTiempo(x['hour'], 1.5, hora_Viaje))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqz1A1D-UXit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Debug\n",
        "print('Total de viajes similares al del cliente alrededor de la hora especificada: ', rddInvierno_viaje.count())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3eIPIb_ahAJ",
        "colab_type": "code",
        "outputId": "994161cc-db64-4910-f0ae-6149cd404bc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Estudiemos ahora las medias en tiempo de todos los viajes similares a esa hora\n",
        "listaTiempos = rddInvierno_viaje.map(lambda x: ([x['travel_time']])).reduce(lambda a, b: a + b)\n",
        "media_tiempo_viaje = stats.mean(listaTiempos)\n",
        "print('La media de tiempo empleado por otros usuarios es: ',media_tiempo_viaje, 'segundos')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La media de tiempo empleado por otros usuarios es:  524.024 segundos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBRMXqxenrbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def estaciones(lista):\n",
        "  filtro = []\n",
        "  for estacion in lista['station']:\n",
        "    if estacion['number'] == origen or estacion['number'] == destino:\n",
        "      filtro.append(estacion)\n",
        "  return {\"day\":lista['day'],\n",
        "          \"hour\":lista['hour'],\n",
        "          \"station\":filtro}\n",
        "\n",
        "rdd_stations['201901a06'] = rdd_stations['201901'].union(rdd_stations['201902'].union(rdd_stations['201903'].union(rdd_stations['201904'].union(rdd_stations['201905'].union(rdd_stations['201906'])))))\n",
        "\n",
        "#rdd_Sit_fil contiene solo los datos de las dos estaciones,\n",
        "#la de partida y la de llegada\n",
        "rdd_Sit_fil = rdd_stations['201901a06'].map(estaciones)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztddV_4JUfcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Debug\n",
        "rdd_Sit_fil.take(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wc5k2Ksci0C",
        "colab_type": "code",
        "outputId": "b8f21f49-29f1-40bc-b0f1-0c6f1d81cf5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "def calcularBasesLibres(lista, n_estacion):\n",
        "  for station in lista:\n",
        "    if station['number'] == n_estacion:\n",
        "      return station['free_bases']\n",
        "\n",
        "def calcularBicisLibres(lista, n_estacion):\n",
        "  for station in lista:\n",
        "    if station['number'] == n_estacion:\n",
        "      return station['dock_bikes']\n",
        "\n",
        "bicisLibres = rdd_Sit_fil.filter(lambda x: rangoTiempo(x['hour'], 1.5, hora_Viaje)).map(lambda x: [calcularBicisLibres(x['station'], origen)]).reduce(lambda a, b: a+b)\n",
        "basesLibres = rdd_Sit_fil.filter(lambda x: rangoTiempo(x['hour'], 1.5, media_tiempo_viaje / 3600.0)).map(lambda x: [calcularBasesLibres(x['station'], destino)]).reduce(lambda a, b: a+b)\n",
        "\n",
        "totalBasesPorEstacion = {}\n",
        "stationsLst = rdd_Sit_fil.take(1)[0]['station']\n",
        "totalBasesPorEstacion[stationsLst[0]['number']] = stationsLst[0]['total_bases']\n",
        "totalBasesPorEstacion[stationsLst[1]['number']] = stationsLst[1]['total_bases']\n",
        "\n",
        "print('La media de bicicletas libres en', origen, 'respecto a la hora elegida es:',int(stats.mean(bicisLibres)), '/', totalBasesPorEstacion[origen])\n",
        "print('La media de bases libres en', destino ,'respecto a la hora estimada de llegada es:',int(stats.mean(basesLibres)), '/', totalBasesPorEstacion[destino])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La media de bicicletas libres en 57 respecto a la hora elegida es: 8 / 24\n",
            "La media de bases libres en 38 respecto a la hora elegida es: 4 / 24\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}